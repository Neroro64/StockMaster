{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import talib\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"../Data/DAX/yahoo_fin/\"\n",
    "\n",
    "def load(filename=\"1d\"):\n",
    "     data = pd.read_csv(PATH+\"{}.csv\".format(filename))\n",
    "     return data\n",
    "def save(filename, data):\n",
    "     data.to_csv(PATH+filename+\".csv\")\n",
    "\n",
    "def normalize(x):\n",
    "    mean = np.mean(x, axis=0, keepdims=True)\n",
    "    std = np.std(x, axis=0, keepdims=True)\n",
    "    return (x - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\"1997-01-01-2020-08-04:1d\")\n",
    "data2 = load(\"1997-01-01-2020-08-04:1wk\")\n",
    "data3 = load(\"1997-01-01-2020-08-04:1mo\")\n",
    "\n",
    "data_all = data.append(data2, ignore_index=True)\n",
    "data_all = data.append(data3, ignore_index=True)\n",
    "data2 = data2.append(data3, ignore_index=True)\n",
    "\n",
    "# print(data.columns)\n",
    "# print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_model(period):\n",
    "    feature_list = [\"1-rad\", \"inter-derivative\", \n",
    "                    \"bb-upper\", \"bb-lower\", \"bb-middle\", \n",
    "                    \"ema-cross\", \"sma-cross\", \n",
    "                    \"macdsignal\", \"macd\", \"macdhist\",\n",
    "                    \"rsi\", \"sar-diff\", \n",
    "                    \"intra-derivative\", \"1-err\", \"intra-diff\"]\n",
    "    \n",
    "    N = len(feature_list)\n",
    "    features = period[feature_list][:-1]\n",
    "    features = np.nan_to_num(features.values)\n",
    "    features = normalize(features)\n",
    "\n",
    "    targets = period[\"inter-diff\"][1:]\n",
    "    targets = targets.values\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, targets, test_size = 0.20, random_state = 2020)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(N),\n",
    "        tf.keras.layers.Dense(128*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(N, activation='relu'),\n",
    "        # tf.keras.layers.Dense(N/2, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "\n",
    "    model.fit(train_features, train_labels, epochs=500, batch_size=100)\n",
    "    model.evaluate(test_features,  test_labels, verbose=2)\n",
    "    model.predict(test_features)\n",
    "    return model\n",
    "\n",
    "def tf_model2(period):\n",
    "    feature_list = [\"1-rad\", \"inter-derivative\", \n",
    "                    \"bb-upper\", \"bb-lower\", \"bb-middle\", \n",
    "                    \"ema-cross\", \"sma-cross\", \n",
    "                    \"macdsignal\", \"macd\", \"macdhist\",\n",
    "                    \"rsi\", \"sar-diff\", \n",
    "                    \"intra-derivative\", \"1-err\", \"intra-diff\"]\n",
    "\n",
    "    N = len(feature_list)\n",
    "    features = period[feature_list][:-1]\n",
    "    features = np.nan_to_num(features.values)\n",
    "    features = normalize(features)\n",
    "\n",
    "    targets = period[\"inter-diff\"][1:]\n",
    "    targets = targets.values\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, targets, test_size = 0.20, random_state = 2020)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(N),\n",
    "        tf.keras.layers.Dense(128*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "\n",
    "    model.fit(train_features, train_labels, epochs=500, batch_size=100, verbose=0)\n",
    "    model.evaluate(test_features,  test_labels, verbose=2)\n",
    "    model.predict(test_features)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " 0.5122\nEpoch 323/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4948 - mean_absolute_error: 0.4948\nEpoch 324/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5360 - mean_absolute_error: 0.5360\nEpoch 325/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4866 - mean_absolute_error: 0.4866\nEpoch 326/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5175 - mean_absolute_error: 0.5175\nEpoch 327/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5337 - mean_absolute_error: 0.5337\nEpoch 328/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5218 - mean_absolute_error: 0.5218\nEpoch 329/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4985 - mean_absolute_error: 0.4985\nEpoch 330/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5224 - mean_absolute_error: 0.5224\nEpoch 331/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5049 - mean_absolute_error: 0.5049\nEpoch 332/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5223 - mean_absolute_error: 0.5223\nEpoch 333/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5242 - mean_absolute_error: 0.5242\nEpoch 334/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5353 - mean_absolute_error: 0.5353\nEpoch 335/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5161 - mean_absolute_error: 0.5161\nEpoch 336/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4901 - mean_absolute_error: 0.4901\nEpoch 337/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4977 - mean_absolute_error: 0.4977\nEpoch 338/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5187 - mean_absolute_error: 0.5187\nEpoch 339/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5175 - mean_absolute_error: 0.5175\nEpoch 340/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4988 - mean_absolute_error: 0.4988\nEpoch 341/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4927 - mean_absolute_error: 0.4927\nEpoch 342/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5289 - mean_absolute_error: 0.5289\nEpoch 343/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5206 - mean_absolute_error: 0.5206\nEpoch 344/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5185 - mean_absolute_error: 0.5185\nEpoch 345/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5066 - mean_absolute_error: 0.5066\nEpoch 346/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4994 - mean_absolute_error: 0.4994\nEpoch 347/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4774 - mean_absolute_error: 0.4774\nEpoch 348/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4902 - mean_absolute_error: 0.4902\nEpoch 349/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4803 - mean_absolute_error: 0.4803\nEpoch 350/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5000 - mean_absolute_error: 0.5000\nEpoch 351/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4745 - mean_absolute_error: 0.4745\nEpoch 352/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5043 - mean_absolute_error: 0.5043\nEpoch 353/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5156 - mean_absolute_error: 0.5156\nEpoch 354/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5015 - mean_absolute_error: 0.5015\nEpoch 355/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5295 - mean_absolute_error: 0.5295\nEpoch 356/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5217 - mean_absolute_error: 0.5217\nEpoch 357/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5070 - mean_absolute_error: 0.5070\nEpoch 358/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5353 - mean_absolute_error: 0.5353\nEpoch 359/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5294 - mean_absolute_error: 0.5294\nEpoch 360/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5098 - mean_absolute_error: 0.5098\nEpoch 361/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5087 - mean_absolute_error: 0.5087\nEpoch 362/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4874 - mean_absolute_error: 0.4874\nEpoch 363/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4861 - mean_absolute_error: 0.4861\nEpoch 364/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5094 - mean_absolute_error: 0.5094\nEpoch 365/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4954 - mean_absolute_error: 0.4954\nEpoch 366/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4968 - mean_absolute_error: 0.4968\nEpoch 367/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5158 - mean_absolute_error: 0.5158\nEpoch 368/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5131 - mean_absolute_error: 0.5131\nEpoch 369/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4961 - mean_absolute_error: 0.4961\nEpoch 370/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5033 - mean_absolute_error: 0.5033\nEpoch 371/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5069 - mean_absolute_error: 0.5069\nEpoch 372/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5182 - mean_absolute_error: 0.5182\nEpoch 373/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4965 - mean_absolute_error: 0.4965\nEpoch 374/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4680 - mean_absolute_error: 0.4680\nEpoch 375/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4837 - mean_absolute_error: 0.4837\nEpoch 376/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5192 - mean_absolute_error: 0.5192\nEpoch 377/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5038 - mean_absolute_error: 0.5038\nEpoch 378/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4814 - mean_absolute_error: 0.4814\nEpoch 379/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4806 - mean_absolute_error: 0.4806\nEpoch 380/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5209 - mean_absolute_error: 0.5209\nEpoch 381/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5180 - mean_absolute_error: 0.5180\nEpoch 382/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5141 - mean_absolute_error: 0.5141\nEpoch 383/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4914 - mean_absolute_error: 0.4914\nEpoch 384/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4754 - mean_absolute_error: 0.4754\nEpoch 385/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4789 - mean_absolute_error: 0.4789\nEpoch 386/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4784 - mean_absolute_error: 0.4784\nEpoch 387/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4682 - mean_absolute_error: 0.4682\nEpoch 388/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4879 - mean_absolute_error: 0.4879\nEpoch 389/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4993 - mean_absolute_error: 0.4993\nEpoch 390/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4929 - mean_absolute_error: 0.4929\nEpoch 391/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4988 - mean_absolute_error: 0.4988\nEpoch 392/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5023 - mean_absolute_error: 0.5023\nEpoch 393/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4940 - mean_absolute_error: 0.4940\nEpoch 394/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4761 - mean_absolute_error: 0.4761\nEpoch 395/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4754 - mean_absolute_error: 0.4754\nEpoch 396/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4965 - mean_absolute_error: 0.4965\nEpoch 397/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4858 - mean_absolute_error: 0.4858\nEpoch 398/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5239 - mean_absolute_error: 0.5239\nEpoch 399/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4832 - mean_absolute_error: 0.4832\nEpoch 400/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4832 - mean_absolute_error: 0.4832\nEpoch 401/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4630 - mean_absolute_error: 0.4630\nEpoch 402/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4734 - mean_absolute_error: 0.4734\nEpoch 403/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4656 - mean_absolute_error: 0.4656\nEpoch 404/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4872 - mean_absolute_error: 0.4872\nEpoch 405/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4752 - mean_absolute_error: 0.4752\nEpoch 406/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4898 - mean_absolute_error: 0.4898\nEpoch 407/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4717 - mean_absolute_error: 0.4717\nEpoch 408/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4904 - mean_absolute_error: 0.4904\nEpoch 409/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4845 - mean_absolute_error: 0.4845\nEpoch 410/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4726 - mean_absolute_error: 0.4726\nEpoch 411/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5031 - mean_absolute_error: 0.5031\nEpoch 412/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4596 - mean_absolute_error: 0.4596\nEpoch 413/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4677 - mean_absolute_error: 0.4677\nEpoch 414/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4847 - mean_absolute_error: 0.4847\nEpoch 415/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4641 - mean_absolute_error: 0.4641\nEpoch 416/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5026 - mean_absolute_error: 0.5026\nEpoch 417/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4758 - mean_absolute_error: 0.4758\nEpoch 418/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4655 - mean_absolute_error: 0.4655\nEpoch 419/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4825 - mean_absolute_error: 0.4825\nEpoch 420/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4903 - mean_absolute_error: 0.4903\nEpoch 421/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4804 - mean_absolute_error: 0.4804\nEpoch 422/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5072 - mean_absolute_error: 0.5072\nEpoch 423/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5085 - mean_absolute_error: 0.5085\nEpoch 424/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4608 - mean_absolute_error: 0.4608\nEpoch 425/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4551 - mean_absolute_error: 0.4551\nEpoch 426/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4516 - mean_absolute_error: 0.4516\nEpoch 427/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4575 - mean_absolute_error: 0.4575\nEpoch 428/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4771 - mean_absolute_error: 0.4771\nEpoch 429/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4793 - mean_absolute_error: 0.4793\nEpoch 430/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4752 - mean_absolute_error: 0.4752\nEpoch 431/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4800 - mean_absolute_error: 0.4800\nEpoch 432/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4636 - mean_absolute_error: 0.4636\nEpoch 433/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4805 - mean_absolute_error: 0.4805\nEpoch 434/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4666 - mean_absolute_error: 0.4666\nEpoch 435/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4696 - mean_absolute_error: 0.4696\nEpoch 436/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4558 - mean_absolute_error: 0.4558\nEpoch 437/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4573 - mean_absolute_error: 0.4573\nEpoch 438/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4454 - mean_absolute_error: 0.4454\nEpoch 439/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4720 - mean_absolute_error: 0.4720\nEpoch 440/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4552 - mean_absolute_error: 0.4552\nEpoch 441/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4883 - mean_absolute_error: 0.4883\nEpoch 442/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4632 - mean_absolute_error: 0.4632\nEpoch 443/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4801 - mean_absolute_error: 0.4801\nEpoch 444/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4781 - mean_absolute_error: 0.4781\nEpoch 445/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4531 - mean_absolute_error: 0.4531\nEpoch 446/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4643 - mean_absolute_error: 0.4643\nEpoch 447/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4529 - mean_absolute_error: 0.4529\nEpoch 448/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4596 - mean_absolute_error: 0.4596\nEpoch 449/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4578 - mean_absolute_error: 0.4578\nEpoch 450/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4488 - mean_absolute_error: 0.4488\nEpoch 451/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4585 - mean_absolute_error: 0.4585\nEpoch 452/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4543 - mean_absolute_error: 0.4543\nEpoch 453/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4526 - mean_absolute_error: 0.4526\nEpoch 454/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4763 - mean_absolute_error: 0.4763\nEpoch 455/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4793 - mean_absolute_error: 0.4793\nEpoch 456/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4787 - mean_absolute_error: 0.4787\nEpoch 457/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4584 - mean_absolute_error: 0.4584\nEpoch 458/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4708 - mean_absolute_error: 0.4708\nEpoch 459/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4712 - mean_absolute_error: 0.4712\nEpoch 460/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4766 - mean_absolute_error: 0.4766\nEpoch 461/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4661 - mean_absolute_error: 0.4661\nEpoch 462/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4539 - mean_absolute_error: 0.4539\nEpoch 463/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4709 - mean_absolute_error: 0.4709\nEpoch 464/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4399 - mean_absolute_error: 0.4399\nEpoch 465/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4826 - mean_absolute_error: 0.4826\nEpoch 466/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4556 - mean_absolute_error: 0.4556\nEpoch 467/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4859 - mean_absolute_error: 0.4859\nEpoch 468/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.5036 - mean_absolute_error: 0.5036\nEpoch 469/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4475 - mean_absolute_error: 0.4475\nEpoch 470/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4480 - mean_absolute_error: 0.4480\nEpoch 471/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4798 - mean_absolute_error: 0.4798\nEpoch 472/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4383 - mean_absolute_error: 0.4383\nEpoch 473/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4503 - mean_absolute_error: 0.4503\nEpoch 474/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4538 - mean_absolute_error: 0.4538\nEpoch 475/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.5097 - mean_absolute_error: 0.5097\nEpoch 476/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4721 - mean_absolute_error: 0.4721\nEpoch 477/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4704 - mean_absolute_error: 0.4704\nEpoch 478/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4731 - mean_absolute_error: 0.4731\nEpoch 479/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4400 - mean_absolute_error: 0.4400\nEpoch 480/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4657 - mean_absolute_error: 0.4657\nEpoch 481/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4712 - mean_absolute_error: 0.4712\nEpoch 482/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4826 - mean_absolute_error: 0.4826\nEpoch 483/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4627 - mean_absolute_error: 0.4627\nEpoch 484/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4416 - mean_absolute_error: 0.4416\nEpoch 485/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4770 - mean_absolute_error: 0.4770\nEpoch 486/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4852 - mean_absolute_error: 0.4852\nEpoch 487/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4409 - mean_absolute_error: 0.4409\nEpoch 488/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4719 - mean_absolute_error: 0.4719\nEpoch 489/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4555 - mean_absolute_error: 0.4555\nEpoch 490/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4515 - mean_absolute_error: 0.4515\nEpoch 491/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4509 - mean_absolute_error: 0.4509\nEpoch 492/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4384 - mean_absolute_error: 0.4384\nEpoch 493/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4668 - mean_absolute_error: 0.4668\nEpoch 494/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4658 - mean_absolute_error: 0.4658\nEpoch 495/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4691 - mean_absolute_error: 0.4691\nEpoch 496/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4389 - mean_absolute_error: 0.4389\nEpoch 497/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4884 - mean_absolute_error: 0.4884\nEpoch 498/500\n13/13 [==============================] - 0s 2ms/step - loss: 0.4670 - mean_absolute_error: 0.4670\nEpoch 499/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4606 - mean_absolute_error: 0.4606\nEpoch 500/500\n13/13 [==============================] - 0s 3ms/step - loss: 0.4816 - mean_absolute_error: 0.4816\n10/10 - 0s - loss: 0.8238 - mean_absolute_error: 0.8238\n"
    }
   ],
   "source": [
    "m1 = tf_model(data2)\n",
    "\n",
    "# m2 = tf_model2(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "187/187 - 0s - loss: 1.9984 - mean_absolute_error: 1.9984\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1.998398780822754, 1.998398780822754]"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "\n",
    "feature_list = [\"1-rad\", \"inter-derivative\", \n",
    "                    \"bb-upper\", \"bb-lower\", \"bb-middle\", \n",
    "                    \"ema-cross\", \"sma-cross\", \n",
    "                    \"macdsignal\", \"macd\", \"macdhist\",\n",
    "                    \"rsi\", \"sar-diff\", \n",
    "                    \"intra-derivative\", \"1-err\", \"intra-diff\"]\n",
    "\n",
    "test_features =  data[feature_list][:-1]\n",
    "test_features = np.nan_to_num(test_features.values)\n",
    "test_features = normalize(test_features)\n",
    "\n",
    "test_labels = data[\"inter-diff\"][1:]\n",
    "m1.evaluate(test_features, test_labels, verbose=2)\n",
    "# m2.evaluate(test_features, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596575893113",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}