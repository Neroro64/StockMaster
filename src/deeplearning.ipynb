{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import talib\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"../Data/DAX/yahoo_fin/\"\n",
    "\n",
    "def load(filename=\"1d\"):\n",
    "     data = pd.read_csv(PATH+\"{}.csv\".format(filename))\n",
    "     return data\n",
    "def save(filename, data):\n",
    "     data.to_csv(PATH+filename+\".csv\")\n",
    "\n",
    "def normalize(x):\n",
    "    mean = np.mean(x, axis=0, keepdims=True)\n",
    "    std = np.std(x, axis=0, keepdims=True)\n",
    "    return (x - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\"1997-01-01-2020-07-31:1d\")\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_model(period):\n",
    "    feature_list = [\"1-rad\", \"inter-derivative\", \n",
    "                    \"bb-upper\", \"bb-lower\", \"bb-middle\", \n",
    "                    \"ema-cross\", \"sma-cross\", \n",
    "                    \"macdsignal\", \"macd\", \"macdhist\",\n",
    "                    \"rsi\", \"sar-diff\", \n",
    "                    \"intra-derivative\", \"1-err\", \"intra-diff\"]\n",
    "    \n",
    "    N = len(feature_list)\n",
    "    features = period[feature_list][:-1]\n",
    "    features = features.values\n",
    "    features = np.nan_to_num(features)\n",
    "    features = normalize(features)\n",
    "\n",
    "    targets = period[\"inter-diff\"][1:]\n",
    "    targets = targets.values\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, targets, test_size = 0.20, random_state = 2020)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(N),\n",
    "        tf.keras.layers.Dense(128*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(N, activation='relu'),\n",
    "\n",
    "        # tf.keras.layers.Dense(N/2, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "\n",
    "    model.fit(train_features, train_labels, epochs=400, batch_size=100, verbose=0)\n",
    "    model.evaluate(test_features,  test_labels, verbose=2)\n",
    "    model.predict(test_features)\n",
    "    return model\n",
    "\n",
    "def tf_model2(period):\n",
    "    feature_list = [\"1-rad\", \"inter-derivative\", \n",
    "                    \"bb-upper\", \"bb-lower\", \"bb-middle\", \n",
    "                    \"ema-cross\", \"sma-cross\", \n",
    "                    \"macdsignal\", \"macd\", \"macdhist\",\n",
    "                    \"rsi\", \"sar-diff\", \n",
    "                    \"intra-derivative\", \"1-err\", \"intra-diff\"]\n",
    "\n",
    "    N = len(feature_list)\n",
    "    features = period[feature_list][:-1]\n",
    "    features = np.nan_to_num(features.values)\n",
    "    features = normalize(features)\n",
    "\n",
    "    targets = period[\"inter-diff\"][1:]\n",
    "    targets = targets.values\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, targets, test_size = 0.20, random_state = 2020)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(N),\n",
    "        tf.keras.layers.Dense(128*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64*N, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "\n",
    "    model.fit(train_features, train_labels, epochs=500, batch_size=100, verbose=0)\n",
    "    model.evaluate(test_features,  test_labels, verbose=2)\n",
    "    model.predict(test_features)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " 29ms/step - loss: 0.2838 - mean_absolute_error: 0.2838\nEpoch 225/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2864 - mean_absolute_error: 0.2864\nEpoch 226/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2874 - mean_absolute_error: 0.2874\nEpoch 227/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2865 - mean_absolute_error: 0.2865\nEpoch 228/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2917 - mean_absolute_error: 0.2917\nEpoch 229/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2894 - mean_absolute_error: 0.2894\nEpoch 230/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2851 - mean_absolute_error: 0.2851\nEpoch 231/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2867 - mean_absolute_error: 0.2867\nEpoch 232/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2852 - mean_absolute_error: 0.2852\nEpoch 233/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2848 - mean_absolute_error: 0.2848\nEpoch 234/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2854 - mean_absolute_error: 0.2854\nEpoch 235/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2818 - mean_absolute_error: 0.2818\nEpoch 236/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2860 - mean_absolute_error: 0.2860\nEpoch 237/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2849 - mean_absolute_error: 0.2849\nEpoch 238/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2879 - mean_absolute_error: 0.2879\nEpoch 239/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2885 - mean_absolute_error: 0.2885\nEpoch 240/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2831 - mean_absolute_error: 0.2831\nEpoch 241/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2817 - mean_absolute_error: 0.2817\nEpoch 242/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2780 - mean_absolute_error: 0.2780\nEpoch 243/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2754 - mean_absolute_error: 0.2754\nEpoch 244/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2797 - mean_absolute_error: 0.2797\nEpoch 245/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2812 - mean_absolute_error: 0.2812\nEpoch 246/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2788 - mean_absolute_error: 0.2788\nEpoch 247/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2835 - mean_absolute_error: 0.2835\nEpoch 248/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2760 - mean_absolute_error: 0.2760\nEpoch 249/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2854 - mean_absolute_error: 0.2854\nEpoch 250/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2814 - mean_absolute_error: 0.2814\nEpoch 251/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2832 - mean_absolute_error: 0.2832\nEpoch 252/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2775 - mean_absolute_error: 0.2775\nEpoch 253/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2806 - mean_absolute_error: 0.2806\nEpoch 254/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2796 - mean_absolute_error: 0.2796\nEpoch 255/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2787 - mean_absolute_error: 0.2787\nEpoch 256/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2795 - mean_absolute_error: 0.2795\nEpoch 257/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2761 - mean_absolute_error: 0.2761\nEpoch 258/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2822 - mean_absolute_error: 0.2822\nEpoch 259/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2766 - mean_absolute_error: 0.2766\nEpoch 260/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2821 - mean_absolute_error: 0.2821\nEpoch 261/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2721 - mean_absolute_error: 0.2721\nEpoch 262/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2773 - mean_absolute_error: 0.2773\nEpoch 263/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2818 - mean_absolute_error: 0.2818\nEpoch 264/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2764 - mean_absolute_error: 0.2764\nEpoch 265/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2770 - mean_absolute_error: 0.2770\nEpoch 266/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2775 - mean_absolute_error: 0.2775\nEpoch 267/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2732 - mean_absolute_error: 0.2732\nEpoch 268/400\n48/48 [==============================] - 1s 28ms/step - loss: 0.2712 - mean_absolute_error: 0.2712\nEpoch 269/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2760 - mean_absolute_error: 0.2760\nEpoch 270/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2748 - mean_absolute_error: 0.2748\nEpoch 271/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2730 - mean_absolute_error: 0.2730\nEpoch 272/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2710 - mean_absolute_error: 0.2710\nEpoch 273/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2712 - mean_absolute_error: 0.2712\nEpoch 274/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2676 - mean_absolute_error: 0.2676\nEpoch 275/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2756 - mean_absolute_error: 0.2756\nEpoch 276/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2721 - mean_absolute_error: 0.2721\nEpoch 277/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2735 - mean_absolute_error: 0.2735\nEpoch 278/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2720 - mean_absolute_error: 0.2720\nEpoch 279/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2732 - mean_absolute_error: 0.2732\nEpoch 280/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2714 - mean_absolute_error: 0.2714\nEpoch 281/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2670 - mean_absolute_error: 0.2670\nEpoch 282/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2710 - mean_absolute_error: 0.2710\nEpoch 283/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2705 - mean_absolute_error: 0.2705\nEpoch 284/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2779 - mean_absolute_error: 0.2779\nEpoch 285/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2663 - mean_absolute_error: 0.2663\nEpoch 286/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2734 - mean_absolute_error: 0.2734\nEpoch 287/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2745 - mean_absolute_error: 0.2745\nEpoch 288/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2731 - mean_absolute_error: 0.2731\nEpoch 289/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2658 - mean_absolute_error: 0.2658\nEpoch 290/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2709 - mean_absolute_error: 0.2709\nEpoch 291/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2661 - mean_absolute_error: 0.2661\nEpoch 292/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2649 - mean_absolute_error: 0.2649\nEpoch 293/400\n48/48 [==============================] - 1s 28ms/step - loss: 0.2660 - mean_absolute_error: 0.2660\nEpoch 294/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2699 - mean_absolute_error: 0.2699\nEpoch 295/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2668 - mean_absolute_error: 0.2668\nEpoch 296/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2673 - mean_absolute_error: 0.2673\nEpoch 297/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2689 - mean_absolute_error: 0.2689\nEpoch 298/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2681 - mean_absolute_error: 0.2681\nEpoch 299/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2670 - mean_absolute_error: 0.2670\nEpoch 300/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2668 - mean_absolute_error: 0.2668\nEpoch 301/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2663 - mean_absolute_error: 0.2663\nEpoch 302/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2667 - mean_absolute_error: 0.2667\nEpoch 303/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2622 - mean_absolute_error: 0.2622\nEpoch 304/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2644 - mean_absolute_error: 0.2644\nEpoch 305/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2631 - mean_absolute_error: 0.2631\nEpoch 306/400\n48/48 [==============================] - 1s 28ms/step - loss: 0.2623 - mean_absolute_error: 0.2623\nEpoch 307/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2611 - mean_absolute_error: 0.2611\nEpoch 308/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2724 - mean_absolute_error: 0.2724\nEpoch 309/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2610 - mean_absolute_error: 0.2610\nEpoch 310/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2581 - mean_absolute_error: 0.2581\nEpoch 311/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2631 - mean_absolute_error: 0.2631\nEpoch 312/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2632 - mean_absolute_error: 0.2632\nEpoch 313/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2598 - mean_absolute_error: 0.2598\nEpoch 314/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2602 - mean_absolute_error: 0.2602\nEpoch 315/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2638 - mean_absolute_error: 0.2638\nEpoch 316/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2607 - mean_absolute_error: 0.2607\nEpoch 317/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2585 - mean_absolute_error: 0.2585\nEpoch 318/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2552 - mean_absolute_error: 0.2552\nEpoch 319/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2631 - mean_absolute_error: 0.2631\nEpoch 320/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2578 - mean_absolute_error: 0.2578\nEpoch 321/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2570 - mean_absolute_error: 0.2570\nEpoch 322/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2604 - mean_absolute_error: 0.2604\nEpoch 323/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2637 - mean_absolute_error: 0.2637\nEpoch 324/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2582 - mean_absolute_error: 0.2582\nEpoch 325/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2691 - mean_absolute_error: 0.2691\nEpoch 326/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2616 - mean_absolute_error: 0.2616\nEpoch 327/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2559 - mean_absolute_error: 0.2559\nEpoch 328/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2571 - mean_absolute_error: 0.2571\nEpoch 329/400\n48/48 [==============================] - 1s 28ms/step - loss: 0.2639 - mean_absolute_error: 0.2639\nEpoch 330/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2612 - mean_absolute_error: 0.2612\nEpoch 331/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2606 - mean_absolute_error: 0.2606\nEpoch 332/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2567 - mean_absolute_error: 0.2567\nEpoch 333/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2559 - mean_absolute_error: 0.2559\nEpoch 334/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2566 - mean_absolute_error: 0.2566\nEpoch 335/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2577 - mean_absolute_error: 0.2577\nEpoch 336/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2568 - mean_absolute_error: 0.2568\nEpoch 337/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2510 - mean_absolute_error: 0.2510\nEpoch 338/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2619 - mean_absolute_error: 0.2619\nEpoch 339/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2568 - mean_absolute_error: 0.2568\nEpoch 340/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2518 - mean_absolute_error: 0.2518\nEpoch 341/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2534 - mean_absolute_error: 0.2534\nEpoch 342/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2616 - mean_absolute_error: 0.2616\nEpoch 343/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2553 - mean_absolute_error: 0.2553\nEpoch 344/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2534 - mean_absolute_error: 0.2534\nEpoch 345/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2543 - mean_absolute_error: 0.2543\nEpoch 346/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2526 - mean_absolute_error: 0.2526\nEpoch 347/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2578 - mean_absolute_error: 0.2578\nEpoch 348/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2565 - mean_absolute_error: 0.2565\nEpoch 349/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2560 - mean_absolute_error: 0.2560\nEpoch 350/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2522 - mean_absolute_error: 0.2522\nEpoch 351/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2557 - mean_absolute_error: 0.2557\nEpoch 352/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2568 - mean_absolute_error: 0.2568\nEpoch 353/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2531 - mean_absolute_error: 0.2531\nEpoch 354/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2525 - mean_absolute_error: 0.2525\nEpoch 355/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2584 - mean_absolute_error: 0.2584\nEpoch 356/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2515 - mean_absolute_error: 0.2515\nEpoch 357/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2565 - mean_absolute_error: 0.2565\nEpoch 358/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2498 - mean_absolute_error: 0.2498\nEpoch 359/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2569 - mean_absolute_error: 0.2569\nEpoch 360/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2542 - mean_absolute_error: 0.2542\nEpoch 361/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2538 - mean_absolute_error: 0.2538\nEpoch 362/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2510 - mean_absolute_error: 0.2510\nEpoch 363/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2497 - mean_absolute_error: 0.2497\nEpoch 364/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2517 - mean_absolute_error: 0.2517\nEpoch 365/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2531 - mean_absolute_error: 0.2531\nEpoch 366/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2542 - mean_absolute_error: 0.2542\nEpoch 367/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2501 - mean_absolute_error: 0.2501\nEpoch 368/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2523 - mean_absolute_error: 0.2523\nEpoch 369/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2500 - mean_absolute_error: 0.2500\nEpoch 370/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2443 - mean_absolute_error: 0.2443\nEpoch 371/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2462 - mean_absolute_error: 0.2462\nEpoch 372/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2508 - mean_absolute_error: 0.2508\nEpoch 373/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2530 - mean_absolute_error: 0.2530\nEpoch 374/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2511 - mean_absolute_error: 0.2511\nEpoch 375/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2463 - mean_absolute_error: 0.2463\nEpoch 376/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2497 - mean_absolute_error: 0.2497\nEpoch 377/400\n48/48 [==============================] - 1s 30ms/step - loss: 0.2477 - mean_absolute_error: 0.2477\nEpoch 378/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2432 - mean_absolute_error: 0.2432\nEpoch 379/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2456 - mean_absolute_error: 0.2456\nEpoch 380/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2532 - mean_absolute_error: 0.2532\nEpoch 381/400\n48/48 [==============================] - 1s 29ms/step - loss: 0.2462 - mean_absolute_error: 0.2462\nEpoch 382/400\n48/48 [==============================] - 1s 27ms/step - loss: 0.2507 - mean_absolute_error: 0.2507\nEpoch 383/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2516 - mean_absolute_error: 0.2516\nEpoch 384/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2489 - mean_absolute_error: 0.2489\nEpoch 385/400\n48/48 [==============================] - 1s 24ms/step - loss: 0.2472 - mean_absolute_error: 0.2472\nEpoch 386/400\n48/48 [==============================] - 1s 24ms/step - loss: 0.2490 - mean_absolute_error: 0.2490\nEpoch 387/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2432 - mean_absolute_error: 0.2432\nEpoch 388/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2499 - mean_absolute_error: 0.2499\nEpoch 389/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2516 - mean_absolute_error: 0.2516\nEpoch 390/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2493 - mean_absolute_error: 0.2493\nEpoch 391/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2442 - mean_absolute_error: 0.2442\nEpoch 392/400\n48/48 [==============================] - 1s 24ms/step - loss: 0.2464 - mean_absolute_error: 0.2464\nEpoch 393/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2411 - mean_absolute_error: 0.2411\nEpoch 394/400\n48/48 [==============================] - 1s 24ms/step - loss: 0.2450 - mean_absolute_error: 0.2450\nEpoch 395/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2453 - mean_absolute_error: 0.2453\nEpoch 396/400\n48/48 [==============================] - 1s 24ms/step - loss: 0.2501 - mean_absolute_error: 0.2501\nEpoch 397/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2445 - mean_absolute_error: 0.2445\nEpoch 398/400\n48/48 [==============================] - 1s 26ms/step - loss: 0.2468 - mean_absolute_error: 0.2468\nEpoch 399/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2420 - mean_absolute_error: 0.2420\nEpoch 400/400\n48/48 [==============================] - 1s 25ms/step - loss: 0.2488 - mean_absolute_error: 0.2488\n38/38 - 0s - loss: 0.3958 - mean_absolute_error: 0.3958\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4b72fd246b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"MLP_1.1\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model = tf_model(data)\n",
    "model.save(PATH+\"MLP_1.1\"+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = manager"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596575893113",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}